{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 2: Fashion MNIST CNN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaliaMelikhov/DL_BackPropagation/blob/master/Fashion_MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYgpzGuMdx8-",
        "colab_type": "text"
      },
      "source": [
        "**Assignment # 2, CNN over Fasion MNIST**\n",
        "\n",
        "In this assignment you are requested to build a convolutional network and train it over the Fasion MNIST data, which is a collection of 28X28 back and white images, classified into 10 different classes of clothing items. For more information about Fashion MNIST you may refer to: \n",
        "https://github.com/zalandoresearch/fashion-mnist "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BibNhZ5ECjS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5w6wIzcd1LG",
        "colab_type": "code",
        "outputId": "5b9b8cb1-e40e-4e20-bf77-32101ce9e34b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "# Loading Fashion MNIST\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import array as arr \n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transforms.ToTensor())\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transforms.ToTensor())\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress',\n",
        "           'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:01, 14761385.87it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 100952.80it/s]           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 4291442.75it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 36538.14it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xs3rDG0xBmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use dataloaders for train and test (batch size is 4)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKOHObeAj99B",
        "colab_type": "code",
        "outputId": "bfdbacee-eaa0-40ec-b0a8-ad029e78e3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The images are of 1, 28, 28 size (only one black-white channel)\n",
        "\n",
        "trainset[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6jH2cjTVnVi",
        "colab_type": "text"
      },
      "source": [
        "Here is what you need to do; you are encoureged to look at notebook \"DL Notebook 9 - CIFAR CNN\" when trying to complete the next steps.\n",
        "\n",
        "\n",
        "Write a network CNNFMnist, that has the following architecture:\n",
        "\n",
        "* Convolution with 10 3X3 filters\n",
        "* Relu\n",
        "* Max pool with 2X2\n",
        "* Convolution with 5 3X3 filters\n",
        "* Relu\n",
        "* Convolution with 16 3X3 filters\n",
        "* Relu\n",
        "* Max pool with 2X2\n",
        "* Liner, output size 128\n",
        "* Relu\n",
        "* Liner, output size 64\n",
        "* Relu\n",
        "* Liner, output size 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoiGc1-donFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNFMnist(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNNFMnist, self).__init__()\n",
        "        #Convolution with 10 3X3 filters\n",
        "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
        "        self.conv2 = nn.Conv2d(10, 5, 3)\n",
        "        self.conv3 = nn.Conv2d(5, 16, 3)\n",
        "\n",
        "        # now a few fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWPM9kvYWmC",
        "colab_type": "text"
      },
      "source": [
        "Write a code that trains the network with FashionMNIST train dataset, for classification (use cross entropy, and SGD).\n",
        "Run the network for at least 10 epochs, over the entire dataset. Make sure to print the loss over the train set as well as the **test set** over time (say, every 1000 batches, but it's up to you), so you will know where you are during training. \n",
        "\n",
        "Note, measuring loss of test is similar to measuring loss over the train test. However, make sure not to run the test images in back propagation. Use them only in forward and calulate the average loss over the entire test set. Since it will make the training process run slower, you should measure loss for the test set only at the end of an epoch (so overall you get 10 loss values for the test set). You are encoureged to write a different function for claculating the loss of the test set, and then call it from the training procedure.\n",
        "\n",
        "\n",
        "You should collect the loss values in an array, so you can plot then into two curves, one for train and one for test.\n",
        "\n",
        "In addition, you should measure the time it takes you to train the network completely.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t2B_0BW_QJ2",
        "colab_type": "code",
        "outputId": "1c093982-938f-472f-86f8-0122da563dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#net = CNNFMnist().cuda()     # -- For GPU\n",
        "net = CNNFMnist()            # -- For CPU\n",
        "\n",
        "print(net)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNNFMnist(\n",
            "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(10, 5, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fexFSc1qkTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_loss_clac():\n",
        "  test_loss = 0.0\n",
        "  for i, data  in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "    #inputs = inputs.cuda() # -- For GPU\n",
        "    #labels = labels.cuda() # -- For GPU\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    test_loss += loss.item()\n",
        "  return test_loss/(len(testloader.dataset))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7MAXSsH67IF",
        "colab_type": "code",
        "outputId": "7c1f4d29-ba05-4a99-940c-3a9e12c71821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(testloader.dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ7qX52gY5-a",
        "colab_type": "code",
        "outputId": "ee8e8158-151e-42d6-e425-266f0e5d0146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# define loss function\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "#train_loss_arr = {}\n",
        "#test_loss_arr = {}\n",
        "train_loss_arr = arr.array('d', []) \n",
        "test_loss_arr = arr.array('d', []) \n",
        "\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "print(\"Training Start Time =\", current_time)\n",
        "\n",
        "for epoch in range(10):  \n",
        "\n",
        "    running_loss = 0.0\n",
        "    epoch_loss = 0.0\n",
        "    test_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        #inputs = inputs.cuda() # -- For GPU\n",
        "        #labels = labels.cuda() # -- For GPU\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        epoch_loss += loss.item()\n",
        "        if (i+1) % 1000 == 0:    \n",
        "            print('[%d, %5d] train loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 1000))\n",
        "            #train_loss_arr.append(running_loss/1000)\n",
        "            running_loss = 0.0\n",
        "\n",
        "    train_loss_arr.append(epoch_loss / len(trainloader.dataset))\n",
        "    epoch_loss = 0.0\n",
        "    test_loss = test_loss_clac()\n",
        "    test_loss_arr.append(test_loss)\n",
        "    print('[%d] test loss: %.3f' %\n",
        "                  (epoch + 1, test_loss))\n",
        "    test_loss =0.0\n",
        "   \n",
        "print('Finished Training')\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "print(\"Training End Time =\", current_time)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Time = 18:02:16\n",
            "[1,  1000] train loss: 2.302\n",
            "[1,  2000] train loss: 2.297\n",
            "[1,  3000] train loss: 1.914\n",
            "[1,  4000] train loss: 0.978\n",
            "[1,  5000] train loss: 0.772\n",
            "[1,  6000] train loss: 0.719\n",
            "[1,  7000] train loss: 0.664\n",
            "[1,  8000] train loss: 0.628\n",
            "[1,  9000] train loss: 0.599\n",
            "[1, 10000] train loss: 0.573\n",
            "[1, 11000] train loss: 0.561\n",
            "[1, 12000] train loss: 0.552\n",
            "[1, 13000] train loss: 0.542\n",
            "[1, 14000] train loss: 0.505\n",
            "[1, 15000] train loss: 0.505\n",
            "[1] test loss: 0.124\n",
            "[2,  1000] train loss: 0.506\n",
            "[2,  2000] train loss: 0.483\n",
            "[2,  3000] train loss: 0.473\n",
            "[2,  4000] train loss: 0.461\n",
            "[2,  5000] train loss: 0.477\n",
            "[2,  6000] train loss: 0.465\n",
            "[2,  7000] train loss: 0.417\n",
            "[2,  8000] train loss: 0.462\n",
            "[2,  9000] train loss: 0.458\n",
            "[2, 10000] train loss: 0.449\n",
            "[2, 11000] train loss: 0.450\n",
            "[2, 12000] train loss: 0.424\n",
            "[2, 13000] train loss: 0.424\n",
            "[2, 14000] train loss: 0.426\n",
            "[2, 15000] train loss: 0.399\n",
            "[2] test loss: 0.106\n",
            "[3,  1000] train loss: 0.393\n",
            "[3,  2000] train loss: 0.374\n",
            "[3,  3000] train loss: 0.382\n",
            "[3,  4000] train loss: 0.420\n",
            "[3,  5000] train loss: 0.383\n",
            "[3,  6000] train loss: 0.381\n",
            "[3,  7000] train loss: 0.394\n",
            "[3,  8000] train loss: 0.388\n",
            "[3,  9000] train loss: 0.378\n",
            "[3, 10000] train loss: 0.396\n",
            "[3, 11000] train loss: 0.378\n",
            "[3, 12000] train loss: 0.378\n",
            "[3, 13000] train loss: 0.386\n",
            "[3, 14000] train loss: 0.364\n",
            "[3, 15000] train loss: 0.368\n",
            "[3] test loss: 0.094\n",
            "[4,  1000] train loss: 0.346\n",
            "[4,  2000] train loss: 0.361\n",
            "[4,  3000] train loss: 0.334\n",
            "[4,  4000] train loss: 0.357\n",
            "[4,  5000] train loss: 0.349\n",
            "[4,  6000] train loss: 0.352\n",
            "[4,  7000] train loss: 0.367\n",
            "[4,  8000] train loss: 0.351\n",
            "[4,  9000] train loss: 0.354\n",
            "[4, 10000] train loss: 0.338\n",
            "[4, 11000] train loss: 0.325\n",
            "[4, 12000] train loss: 0.336\n",
            "[4, 13000] train loss: 0.360\n",
            "[4, 14000] train loss: 0.335\n",
            "[4, 15000] train loss: 0.339\n",
            "[4] test loss: 0.109\n",
            "[5,  1000] train loss: 0.336\n",
            "[5,  2000] train loss: 0.330\n",
            "[5,  3000] train loss: 0.329\n",
            "[5,  4000] train loss: 0.325\n",
            "[5,  5000] train loss: 0.342\n",
            "[5,  6000] train loss: 0.339\n",
            "[5,  7000] train loss: 0.330\n",
            "[5,  8000] train loss: 0.307\n",
            "[5,  9000] train loss: 0.318\n",
            "[5, 10000] train loss: 0.303\n",
            "[5, 11000] train loss: 0.323\n",
            "[5, 12000] train loss: 0.323\n",
            "[5, 13000] train loss: 0.310\n",
            "[5, 14000] train loss: 0.334\n",
            "[5, 15000] train loss: 0.313\n",
            "[5] test loss: 0.088\n",
            "[6,  1000] train loss: 0.309\n",
            "[6,  2000] train loss: 0.284\n",
            "[6,  3000] train loss: 0.321\n",
            "[6,  4000] train loss: 0.317\n",
            "[6,  5000] train loss: 0.310\n",
            "[6,  6000] train loss: 0.299\n",
            "[6,  7000] train loss: 0.301\n",
            "[6,  8000] train loss: 0.306\n",
            "[6,  9000] train loss: 0.327\n",
            "[6, 10000] train loss: 0.329\n",
            "[6, 11000] train loss: 0.305\n",
            "[6, 12000] train loss: 0.309\n",
            "[6, 13000] train loss: 0.305\n",
            "[6, 14000] train loss: 0.306\n",
            "[6, 15000] train loss: 0.282\n",
            "[6] test loss: 0.081\n",
            "[7,  1000] train loss: 0.285\n",
            "[7,  2000] train loss: 0.304\n",
            "[7,  3000] train loss: 0.292\n",
            "[7,  4000] train loss: 0.287\n",
            "[7,  5000] train loss: 0.297\n",
            "[7,  6000] train loss: 0.283\n",
            "[7,  7000] train loss: 0.271\n",
            "[7,  8000] train loss: 0.305\n",
            "[7,  9000] train loss: 0.284\n",
            "[7, 10000] train loss: 0.293\n",
            "[7, 11000] train loss: 0.313\n",
            "[7, 12000] train loss: 0.302\n",
            "[7, 13000] train loss: 0.281\n",
            "[7, 14000] train loss: 0.290\n",
            "[7, 15000] train loss: 0.292\n",
            "[7] test loss: 0.082\n",
            "[8,  1000] train loss: 0.261\n",
            "[8,  2000] train loss: 0.293\n",
            "[8,  3000] train loss: 0.277\n",
            "[8,  4000] train loss: 0.288\n",
            "[8,  5000] train loss: 0.279\n",
            "[8,  6000] train loss: 0.303\n",
            "[8,  7000] train loss: 0.263\n",
            "[8,  8000] train loss: 0.291\n",
            "[8,  9000] train loss: 0.276\n",
            "[8, 10000] train loss: 0.276\n",
            "[8, 11000] train loss: 0.292\n",
            "[8, 12000] train loss: 0.289\n",
            "[8, 13000] train loss: 0.268\n",
            "[8, 14000] train loss: 0.271\n",
            "[8, 15000] train loss: 0.277\n",
            "[8] test loss: 0.093\n",
            "[9,  1000] train loss: 0.283\n",
            "[9,  2000] train loss: 0.263\n",
            "[9,  3000] train loss: 0.268\n",
            "[9,  4000] train loss: 0.279\n",
            "[9,  5000] train loss: 0.269\n",
            "[9,  6000] train loss: 0.275\n",
            "[9,  7000] train loss: 0.271\n",
            "[9,  8000] train loss: 0.275\n",
            "[9,  9000] train loss: 0.284\n",
            "[9, 10000] train loss: 0.254\n",
            "[9, 11000] train loss: 0.280\n",
            "[9, 12000] train loss: 0.265\n",
            "[9, 13000] train loss: 0.272\n",
            "[9, 14000] train loss: 0.267\n",
            "[9, 15000] train loss: 0.264\n",
            "[9] test loss: 0.080\n",
            "[10,  1000] train loss: 0.278\n",
            "[10,  2000] train loss: 0.243\n",
            "[10,  3000] train loss: 0.252\n",
            "[10,  4000] train loss: 0.253\n",
            "[10,  5000] train loss: 0.254\n",
            "[10,  6000] train loss: 0.242\n",
            "[10,  7000] train loss: 0.269\n",
            "[10,  8000] train loss: 0.271\n",
            "[10,  9000] train loss: 0.280\n",
            "[10, 10000] train loss: 0.281\n",
            "[10, 11000] train loss: 0.270\n",
            "[10, 12000] train loss: 0.278\n",
            "[10, 13000] train loss: 0.254\n",
            "[10, 14000] train loss: 0.267\n",
            "[10, 15000] train loss: 0.263\n",
            "[10] test loss: 0.076\n",
            "Finished Training\n",
            "Training Time = 18:12:57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omtuDAivc5Vl",
        "colab_type": "code",
        "outputId": "abb17975-1bcb-4620-9057-e65294be3408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "\n",
        "print(train_loss_arr)\n",
        "print(test_loss_arr)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(10), train_loss_arr, 'b', label='Training Loss')\n",
        "plt.plot(range(10), test_loss_arr, 'r', label='Test Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Test Loss')\n",
        "plt.savefig('./foo.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array('d', [0.23517404237181957, 0.11290024231211356, 0.09606405043247457, 0.08674542127293529, 0.08105915506762684, 0.07684484313333845, 0.07300914431889087, 0.07004094726718674, 0.06778524259818258, 0.06592401163524272])\n",
            "array('d', [0.12419063698211685, 0.10641429917731439, 0.09379798705044741, 0.10880577322118952, 0.08751797830163151, 0.08092370106894141, 0.08197493506741982, 0.09338848924289832, 0.08048161948949667, 0.0759335251848664])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMoAAAEICAYAAAAeMmujAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa0sxqAhY8wA",
        "colab_type": "text"
      },
      "source": [
        "Write a function that evaluates the resulted model over the entire test data of FashionMNIST. Provide a single accuracy number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzuGund9aBOp",
        "colab_type": "code",
        "outputId": "98c539d1-05fb-4b9f-fbb0-062cadb827ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        #images = images.cuda()  # -- for GPU\n",
        "        #labels = labels.cuda()  # -- for GPU\n",
        "\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 89 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMnb9gSGaIjP",
        "colab_type": "text"
      },
      "source": [
        "# Training with a GPU \n",
        "You are requested to change your code to use the GPU instead of the CPU.\n",
        "This can be easily done bu converting every torch.tensor to torch.cuda.tensor. \n",
        "\n",
        "Specific instructions:\n",
        "* Change the hardware equipent of your colab notebook. To do that, go to the \"Runtime\" menu, and then to \"Change runtime type\". In the dialog box, change \"Hardware accelerator\" to GPU.\n",
        "* Please follow the lines that were commented out with the comment    # -- For GPU\n",
        "* Also, remove the lines that have the comment # -- For CPU\n",
        "\n",
        "Train your network again and compare training time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm5DnMate6s0",
        "colab_type": "text"
      },
      "source": [
        "# Submission instructions\n",
        "\n",
        "You should submit a pdf file with the following items:\n",
        "\n",
        "CPU Experiment:\n",
        "*   Plot of loss curves (train in blue, test in red)\n",
        "*   Training time\n",
        "\n",
        "GPU Experiment:\n",
        "*   Plot of loss curves (train in blue, test in red)\n",
        "*   Training time\n",
        "\n",
        "Link for your collab notebook.\n",
        "ID and names of submitters.\n",
        "\n",
        "\n",
        "Good luck!"
      ]
    }
  ]
}